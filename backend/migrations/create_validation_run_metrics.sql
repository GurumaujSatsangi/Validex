-- Migration: Create validation_run_metrics table
-- Purpose: Store LangSmith metrics (latency, token usage, cost) for validation runs
-- Date: 2026-02-06

-- Create validation_run_metrics table
CREATE TABLE IF NOT EXISTS validation_run_metrics (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  
  -- Foreign keys
  provider_id UUID REFERENCES providers(id) ON DELETE CASCADE,
  run_id UUID REFERENCES validation_runs(id) ON DELETE CASCADE,
  
  -- Latency metrics
  workflow_latency_ms INTEGER NOT NULL,
  per_node_latency JSONB DEFAULT '[]'::jsonb,
  
  -- Token usage metrics
  total_tokens INTEGER DEFAULT 0,
  prompt_tokens INTEGER DEFAULT 0,
  completion_tokens INTEGER DEFAULT 0,
  
  -- Cost metrics
  estimated_cost_usd DECIMAL(10, 6) DEFAULT 0.0,
  
  -- Metadata
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  
  -- Indexes
  CONSTRAINT valid_latency CHECK (workflow_latency_ms >= 0),
  CONSTRAINT valid_tokens CHECK (
    total_tokens >= 0 AND 
    prompt_tokens >= 0 AND 
    completion_tokens >= 0
  ),
  CONSTRAINT valid_cost CHECK (estimated_cost_usd >= 0)
);

-- Create indexes for common queries
CREATE INDEX idx_validation_run_metrics_provider_id ON validation_run_metrics(provider_id);
CREATE INDEX idx_validation_run_metrics_run_id ON validation_run_metrics(run_id);
CREATE INDEX idx_validation_run_metrics_created_at ON validation_run_metrics(created_at DESC);

-- Create composite index for reporting queries
CREATE INDEX idx_validation_run_metrics_created_provider ON validation_run_metrics(created_at DESC, provider_id);

-- Add comments
COMMENT ON TABLE validation_run_metrics IS 'Stores LangSmith metrics for validation runs including latency, token usage, and cost estimates';
COMMENT ON COLUMN validation_run_metrics.workflow_latency_ms IS 'Total workflow execution time in milliseconds';
COMMENT ON COLUMN validation_run_metrics.per_node_latency IS 'JSON array of per-node latency: [{ name, run_type, latency_ms }]';
COMMENT ON COLUMN validation_run_metrics.total_tokens IS 'Total tokens used (prompt + completion)';
COMMENT ON COLUMN validation_run_metrics.prompt_tokens IS 'Input tokens sent to LLM';
COMMENT ON COLUMN validation_run_metrics.completion_tokens IS 'Output tokens generated by LLM';
COMMENT ON COLUMN validation_run_metrics.estimated_cost_usd IS 'Estimated cost in USD based on token pricing';

-- Example queries

-- 1. Get metrics for a specific run
-- SELECT * FROM validation_run_metrics WHERE run_id = 'your-run-id-here';

-- 2. Get average latency per provider
-- SELECT 
--   provider_id,
--   COUNT(*) as validation_count,
--   AVG(workflow_latency_ms) as avg_latency_ms,
--   SUM(total_tokens) as total_tokens,
--   SUM(estimated_cost_usd) as total_cost
-- FROM validation_run_metrics
-- GROUP BY provider_id
-- ORDER BY total_cost DESC;

-- 3. Get daily metrics summary
-- SELECT 
--   DATE(created_at) as date,
--   COUNT(*) as runs,
--   AVG(workflow_latency_ms) as avg_latency_ms,
--   SUM(total_tokens) as total_tokens,
--   SUM(estimated_cost_usd) as total_cost_usd
-- FROM validation_run_metrics
-- WHERE created_at >= NOW() - INTERVAL '30 days'
-- GROUP BY DATE(created_at)
-- ORDER BY date DESC;

-- 4. Get high-cost validation runs
-- SELECT 
--   vrm.*,
--   p.name as provider_name,
--   vr.started_at as run_started_at
-- FROM validation_run_metrics vrm
-- JOIN providers p ON vrm.provider_id = p.id
-- JOIN validation_runs vr ON vrm.run_id = vr.id
-- WHERE vrm.estimated_cost_usd > 0.01
-- ORDER BY vrm.estimated_cost_usd DESC
-- LIMIT 20;

-- 5. Get node-level latency breakdown
-- SELECT 
--   run_id,
--   jsonb_array_elements(per_node_latency) as node_info
-- FROM validation_run_metrics
-- WHERE run_id = 'your-run-id-here';
